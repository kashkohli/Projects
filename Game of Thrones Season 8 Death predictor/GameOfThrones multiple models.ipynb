{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from keras.optimizers import SGD\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeX = pd.read_csv('character-predictions.csv', usecols= [7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "dataframeY = pd.read_csv('character-predictions.csv', usecols=[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   male  book1  book2  book3  book4  book5  isMarried  isNoble  \\\n",
      "0     1      0      0      0      0      0          0        0   \n",
      "1     1      1      1      1      1      1          1        1   \n",
      "2     1      0      0      0      1      0          0        1   \n",
      "3     0      0      0      0      0      0          1        1   \n",
      "4     0      0      0      0      1      0          1        1   \n",
      "\n",
      "   numDeadRelations  boolDeadRelations  isPopular  popularity  \n",
      "0                11                  1          1    0.605351  \n",
      "1                 1                  1          1    0.896321  \n",
      "2                 0                  0          0    0.267559  \n",
      "3                 0                  0          0    0.183946  \n",
      "4                 0                  0          0    0.043478  \n",
      "   isAlive\n",
      "0        0\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n"
     ]
    }
   ],
   "source": [
    "print(dataframeX.head(5))\n",
    "print(dataframeY.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataframeX.values, dataframeY.values, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01003344],\n",
      "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
      "        0.8361204 ],\n",
      "       [1.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
      "        0.06354515],\n",
      "       ...,\n",
      "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
      "        1.        ],\n",
      "       [1.        , 1.        , 1.        , ..., 1.        , 0.        ,\n",
      "        0.12040134],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.04013378],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.04682274],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.0367893 ],\n",
      "       ...,\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01337793],\n",
      "       [1.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
      "        0.04347826],\n",
      "       [1.        , 1.        , 0.        , ..., 1.        , 1.        ,\n",
      "        0.48829431]]))\n"
     ]
    }
   ],
   "source": [
    "print(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[-1.2795656 , -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.49172859],\n",
      "       [ 0.78151522,  2.0008037 ,  1.31340922, ...,  3.42842506,\n",
      "         4.16003394,  4.83470059],\n",
      "       [ 0.78151522,  2.0008037 ,  1.31340922, ..., -0.29167912,\n",
      "        -0.24038265, -0.14669674],\n",
      "       ...,\n",
      "       [ 0.78151522,  2.0008037 ,  1.31340922, ...,  3.42842506,\n",
      "         4.16003394,  5.89136063],\n",
      "       [ 0.78151522,  2.0008037 ,  1.31340922, ...,  3.42842506,\n",
      "        -0.24038265,  0.2198996 ],\n",
      "       [-1.2795656 , -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.55642207]]), array([[ 0.78151522, -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.29764818],\n",
      "       [ 0.78151522, -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.2545192 ],\n",
      "       [ 0.78151522, -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.31921267],\n",
      "       ...,\n",
      "       [ 0.78151522, -0.49979916, -0.76137733, ..., -0.29167912,\n",
      "        -0.24038265, -0.4701641 ],\n",
      "       [ 0.78151522, -0.49979916,  1.31340922, ..., -0.29167912,\n",
      "        -0.24038265, -0.27608369],\n",
      "       [ 0.78151522,  2.0008037 , -0.76137733, ...,  3.42842506,\n",
      "         4.16003394,  2.59199357]]))\n"
     ]
    }
   ],
   "source": [
    "print(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(15, input_dim=12, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(15, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(50, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(50, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(15, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                800       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                765       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 4,566\n",
      "Trainable params: 4,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 - Adam - Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 514us/step - loss: 0.2100 - acc: 0.7288\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1781 - acc: 0.7461\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1678 - acc: 0.7564\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.1632 - acc: 0.7654\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.1605 - acc: 0.7699\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1572 - acc: 0.7738\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.1551 - acc: 0.7783\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1539 - acc: 0.7834\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1521 - acc: 0.7834\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1503 - acc: 0.7918\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1498 - acc: 0.7892\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1489 - acc: 0.7898\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1482 - acc: 0.7898\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1464 - acc: 0.7969\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1449 - acc: 0.7950\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1453 - acc: 0.7969\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1429 - acc: 0.7976\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1421 - acc: 0.8001\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1409 - acc: 0.8033\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1395 - acc: 0.8066\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1385 - acc: 0.8021\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1399 - acc: 0.8001\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1386 - acc: 0.8085\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1375 - acc: 0.8072\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1380 - acc: 0.8033\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1358 - acc: 0.8098\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1356 - acc: 0.8149\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1356 - acc: 0.8123\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1352 - acc: 0.8072\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1348 - acc: 0.8059\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1325 - acc: 0.8156\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1348 - acc: 0.8123\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1322 - acc: 0.8123\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.1311 - acc: 0.8098\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1290 - acc: 0.8188\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1307 - acc: 0.8149\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1305 - acc: 0.8220\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1331 - acc: 0.8149\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1284 - acc: 0.8194\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1278 - acc: 0.8162\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1279 - acc: 0.8123\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1284 - acc: 0.8168\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1258 - acc: 0.8233\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1259 - acc: 0.8181\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1251 - acc: 0.8258\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1269 - acc: 0.8265\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1247 - acc: 0.8233\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1264 - acc: 0.8220\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1233 - acc: 0.8329\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1221 - acc: 0.8271\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1258 - acc: 0.8188\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1219 - acc: 0.8329\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1246 - acc: 0.8297\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1205 - acc: 0.8355\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1230 - acc: 0.8252\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1202 - acc: 0.8335\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1206 - acc: 0.8310\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1225 - acc: 0.8284\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.1197 - acc: 0.8393\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1185 - acc: 0.8393\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1188 - acc: 0.8361\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1182 - acc: 0.8361\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1195 - acc: 0.8361\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1191 - acc: 0.8342\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1163 - acc: 0.8406\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1172 - acc: 0.8419\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1192 - acc: 0.8335\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.1191 - acc: 0.8374\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1173 - acc: 0.8413\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1151 - acc: 0.8419\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1159 - acc: 0.8406\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1184 - acc: 0.8393\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1172 - acc: 0.8406\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1155 - acc: 0.8432\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1152 - acc: 0.8451\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1132 - acc: 0.8503\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1124 - acc: 0.8438\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1114 - acc: 0.8464\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1135 - acc: 0.8451\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1150 - acc: 0.8483\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1135 - acc: 0.8477\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1132 - acc: 0.8483\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1150 - acc: 0.8419\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1113 - acc: 0.8483\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1120 - acc: 0.8483\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1132 - acc: 0.8458\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.1127 - acc: 0.8496\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1098 - acc: 0.8496\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1127 - acc: 0.8425\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1108 - acc: 0.8458\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1082 - acc: 0.8509\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1111 - acc: 0.8522\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1080 - acc: 0.8554\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1070 - acc: 0.8554\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.1067 - acc: 0.8554\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1096 - acc: 0.8509\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.1085 - acc: 0.8515\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.1097 - acc: 0.8528\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.1130 - acc: 0.8425\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.1082 - acc: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb292754d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=50,  verbose=1, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_meansqerror.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 52  35]\n",
      " [ 32 271]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 82.82%\n"
     ]
    }
   ],
   "source": [
    "acs = accuracy_score(Y_test, Y_pred)\n",
    "print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 - Adam - Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 91us/step - loss: 0.4149 - acc: 0.8393\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4078 - acc: 0.8387\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4094 - acc: 0.8297\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4044 - acc: 0.8329\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4045 - acc: 0.8239\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4021 - acc: 0.8342\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4009 - acc: 0.8271\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4005 - acc: 0.8303\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3995 - acc: 0.8303\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3990 - acc: 0.8329\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 22us/step - loss: 0.3985 - acc: 0.8284\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3971 - acc: 0.8342\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 22us/step - loss: 0.3959 - acc: 0.8303\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3946 - acc: 0.8387\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3951 - acc: 0.8310\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3942 - acc: 0.8265\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3928 - acc: 0.8342\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3924 - acc: 0.8342\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3920 - acc: 0.8348\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3909 - acc: 0.8335\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3903 - acc: 0.8355\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3915 - acc: 0.8303\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3922 - acc: 0.8380\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3892 - acc: 0.8342\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3875 - acc: 0.8348\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3887 - acc: 0.8290\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3891 - acc: 0.8368\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3900 - acc: 0.8393\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3866 - acc: 0.8329\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3858 - acc: 0.8400\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3847 - acc: 0.8374\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3835 - acc: 0.8374\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3844 - acc: 0.8380\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3850 - acc: 0.8387\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3846 - acc: 0.8400\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3821 - acc: 0.8374\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3820 - acc: 0.8355\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3826 - acc: 0.8355\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3828 - acc: 0.8400\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3808 - acc: 0.8335\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3825 - acc: 0.8368\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3800 - acc: 0.8374\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3793 - acc: 0.8380\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3803 - acc: 0.8348\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3821 - acc: 0.8342\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3781 - acc: 0.8374\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3802 - acc: 0.8380\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3788 - acc: 0.8387\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3795 - acc: 0.8323\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3777 - acc: 0.8406\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3762 - acc: 0.8380\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3771 - acc: 0.8406\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3752 - acc: 0.8335\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3771 - acc: 0.8348\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3750 - acc: 0.8406\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3754 - acc: 0.8374\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3737 - acc: 0.8387\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3753 - acc: 0.8368\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3746 - acc: 0.8413\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3775 - acc: 0.8368\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3743 - acc: 0.8393\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3721 - acc: 0.8380\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3718 - acc: 0.8406\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3740 - acc: 0.8368\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3726 - acc: 0.8406\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3731 - acc: 0.8355\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3727 - acc: 0.8419\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3706 - acc: 0.8419\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3696 - acc: 0.8342\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3732 - acc: 0.8348\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.3751 - acc: 0.8432\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3717 - acc: 0.8400\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.3693 - acc: 0.8380\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3707 - acc: 0.8445\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3684 - acc: 0.8445\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3699 - acc: 0.8361\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3683 - acc: 0.8425\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3691 - acc: 0.8413\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3689 - acc: 0.8387\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3691 - acc: 0.8438\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3677 - acc: 0.8406\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3668 - acc: 0.8432\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3663 - acc: 0.8368\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3658 - acc: 0.8425\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3661 - acc: 0.8458\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3667 - acc: 0.8419\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3646 - acc: 0.8432\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.3638 - acc: 0.8483\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3666 - acc: 0.8400\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 22us/step - loss: 0.3647 - acc: 0.8438\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3638 - acc: 0.8496\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3647 - acc: 0.8438\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.3663 - acc: 0.8419\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3645 - acc: 0.8438\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3639 - acc: 0.8451\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3635 - acc: 0.8432\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3625 - acc: 0.8464\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3631 - acc: 0.8470\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3637 - acc: 0.8451\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3613 - acc: 0.8445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddc80d6850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_binarycrossentropy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 76.41%\n"
     ]
    }
   ],
   "source": [
    "acs = accuracy_score(Y_test, Y_pred)\n",
    "print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - SGD - Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_to_test = [.000001, .01, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 227us/step - loss: 0.6950 - acc: 0.4524\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4531\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6949 - acc: 0.4537\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4544\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4544\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6949 - acc: 0.4544\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6949 - acc: 0.4544\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6948 - acc: 0.4544\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6948 - acc: 0.4544\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6948 - acc: 0.4544\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6948 - acc: 0.4544\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6948 - acc: 0.4544\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6948 - acc: 0.4550\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6948 - acc: 0.4557\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6947 - acc: 0.4557\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6947 - acc: 0.4563\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6947 - acc: 0.4563\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6947 - acc: 0.4563\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6947 - acc: 0.4563\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6947 - acc: 0.4595\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6947 - acc: 0.4595\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6947 - acc: 0.4595\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.6947 - acc: 0.4595\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6947 - acc: 0.4595\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6946 - acc: 0.4595\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6946 - acc: 0.4595\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6946 - acc: 0.4595\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6946 - acc: 0.4595\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6946 - acc: 0.4595\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6946 - acc: 0.4602\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6945 - acc: 0.4602\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6945 - acc: 0.4602\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6945 - acc: 0.4602\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.6945 - acc: 0.4602\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.4602\n",
      "\n",
      "Accuracy Score: 36.41%\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 512us/step - loss: 0.6775 - acc: 0.6722\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.6493 - acc: 0.7301\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.6292 - acc: 0.7326\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6154 - acc: 0.7326\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6047 - acc: 0.7326\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.5966 - acc: 0.7326\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5909 - acc: 0.7326\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5864 - acc: 0.7326\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5827 - acc: 0.7326\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.5795 - acc: 0.7326\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.5768 - acc: 0.7326\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.5743 - acc: 0.7326\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5721 - acc: 0.7326\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.5700 - acc: 0.7326\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5680 - acc: 0.7326\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.5658 - acc: 0.7326\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5636 - acc: 0.7326\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5615 - acc: 0.7326\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5591 - acc: 0.7326\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5567 - acc: 0.7326\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5542 - acc: 0.7326\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5517 - acc: 0.7333\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5491 - acc: 0.7352\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5466 - acc: 0.7365\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5439 - acc: 0.7384\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5413 - acc: 0.7404\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5385 - acc: 0.7404\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5362 - acc: 0.7410\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5336 - acc: 0.7423\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5310 - acc: 0.7410\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5284 - acc: 0.7404\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.5263 - acc: 0.7436\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5243 - acc: 0.7436\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5221 - acc: 0.7442\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5201 - acc: 0.7436\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5183 - acc: 0.7423\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5165 - acc: 0.7436\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5148 - acc: 0.7442\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5128 - acc: 0.7449\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5114 - acc: 0.7455\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5099 - acc: 0.7455\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5083 - acc: 0.7442\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5070 - acc: 0.7442\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.5055 - acc: 0.7442\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.5041 - acc: 0.7442\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5026 - acc: 0.7416\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.5013 - acc: 0.7449\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.5001 - acc: 0.7455\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4990 - acc: 0.7468\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4977 - acc: 0.7468\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4966 - acc: 0.7494\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4954 - acc: 0.7487\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4941 - acc: 0.7519\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4933 - acc: 0.7513\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4919 - acc: 0.7500\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4910 - acc: 0.7506\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4897 - acc: 0.7500\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4888 - acc: 0.7513\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4877 - acc: 0.7526\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4869 - acc: 0.7526\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4859 - acc: 0.7539\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4852 - acc: 0.7564\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4842 - acc: 0.7558\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4834 - acc: 0.7577\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4826 - acc: 0.7577\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 57us/step - loss: 0.4820 - acc: 0.7596\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4808 - acc: 0.7629\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4799 - acc: 0.7564\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.4791 - acc: 0.7609\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4785 - acc: 0.7616\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4780 - acc: 0.7616\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4777 - acc: 0.7596\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 53us/step - loss: 0.4768 - acc: 0.7635\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4760 - acc: 0.7648\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4754 - acc: 0.7629\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4746 - acc: 0.7629\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4739 - acc: 0.7641\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4736 - acc: 0.7629\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4729 - acc: 0.7641\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4722 - acc: 0.7693\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4717 - acc: 0.7699\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4713 - acc: 0.7706\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4706 - acc: 0.7757\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4698 - acc: 0.7693\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4691 - acc: 0.7686\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4687 - acc: 0.7783\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4681 - acc: 0.7686\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4680 - acc: 0.7699\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4670 - acc: 0.7796\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4666 - acc: 0.7699\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4665 - acc: 0.7757\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4657 - acc: 0.7731\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4653 - acc: 0.7757\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4648 - acc: 0.7783\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.4643 - acc: 0.7808\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4635 - acc: 0.7834\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4629 - acc: 0.7802\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4629 - acc: 0.7763\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4623 - acc: 0.7776\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4624 - acc: 0.7789\n",
      "\n",
      "Accuracy Score: 80.51%\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 252us/step - loss: 0.5691 - acc: 0.7153\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.4986 - acc: 0.7461\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4948 - acc: 0.7455\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4917 - acc: 0.7629\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4956 - acc: 0.7564\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.4785 - acc: 0.7674\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.4803 - acc: 0.7596\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4640 - acc: 0.7815\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4607 - acc: 0.7802\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4668 - acc: 0.7841\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.4655 - acc: 0.7815\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4701 - acc: 0.7757\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4594 - acc: 0.7866\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4706 - acc: 0.7674\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4585 - acc: 0.7783\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5391 - acc: 0.7384\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4788 - acc: 0.7706\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4690 - acc: 0.7828\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4588 - acc: 0.7898\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4579 - acc: 0.7905\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.4585 - acc: 0.7841\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.4543 - acc: 0.7886\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4487 - acc: 0.8001\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4443 - acc: 0.7976\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4495 - acc: 0.8014\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4497 - acc: 0.7886\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4510 - acc: 0.7982\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4697 - acc: 0.7866\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4460 - acc: 0.7995\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4429 - acc: 0.7931\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4421 - acc: 0.8008\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4460 - acc: 0.7995\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4500 - acc: 0.7892\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4451 - acc: 0.7982\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4736 - acc: 0.7763\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4349 - acc: 0.8040\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4372 - acc: 0.7976\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4339 - acc: 0.7995\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4349 - acc: 0.8008\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4824 - acc: 0.7674\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4421 - acc: 0.7860\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4441 - acc: 0.7886\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4364 - acc: 0.8001\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4253 - acc: 0.8021\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.4302 - acc: 0.7969\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4799 - acc: 0.7333\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4789 - acc: 0.7513\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4591 - acc: 0.7763\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4436 - acc: 0.7937\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4352 - acc: 0.7969\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4373 - acc: 0.7905\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4527 - acc: 0.7770\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4313 - acc: 0.7911\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.4367 - acc: 0.7956\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4277 - acc: 0.8001\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4242 - acc: 0.8053\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4320 - acc: 0.8104\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.4148 - acc: 0.8104\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4308 - acc: 0.7931\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4184 - acc: 0.8123\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4192 - acc: 0.8085\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4312 - acc: 0.8040\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4239 - acc: 0.8066: 0s - loss: 0.4092 - acc: 0.818\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4130 - acc: 0.8085\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4133 - acc: 0.8078\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4233 - acc: 0.8098\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4145 - acc: 0.8111\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4312 - acc: 0.7860\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4156 - acc: 0.8168\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4145 - acc: 0.8091\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4256 - acc: 0.8033\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.4696 - acc: 0.7924\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4663 - acc: 0.7596\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4583 - acc: 0.7757\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4399 - acc: 0.7995\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4255 - acc: 0.8027\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4265 - acc: 0.7956\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4267 - acc: 0.8008\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4459 - acc: 0.7886\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4188 - acc: 0.8046\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4302 - acc: 0.8027\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4078 - acc: 0.8156\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4163 - acc: 0.8149\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4104 - acc: 0.8194\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4102 - acc: 0.8078\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4227 - acc: 0.8098\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4052 - acc: 0.8149\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4116 - acc: 0.8181\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4376 - acc: 0.8014\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.6281 - acc: 0.7134\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4982 - acc: 0.7429\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.5084 - acc: 0.7449\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.5041 - acc: 0.7455\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4916 - acc: 0.7429\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5396 - acc: 0.7275\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4740 - acc: 0.7416\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.5263 - acc: 0.7526\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4821 - acc: 0.7641\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4714 - acc: 0.7622\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4640 - acc: 0.7667\n",
      "\n",
      "Accuracy Score: 79.74%\n"
     ]
    }
   ],
   "source": [
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    model.compile(optimizer = my_optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred = (Y_pred > 0.5)\n",
    "    acs = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - SGD - Mean Sq Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_to_test = [.000001, .01, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 294us/step - loss: 0.6763 - acc: 0.7326\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6763 - acc: 0.7326\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6763 - acc: 0.7326\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6763 - acc: 0.7326\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.6762 - acc: 0.7326\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6761 - acc: 0.7326\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6760 - acc: 0.7326\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.6760 - acc: 0.7326\n",
      "\n",
      "Accuracy Score: 79.74%\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 383us/step - loss: 0.6642 - acc: 0.7326\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.6403 - acc: 0.7326\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.6236 - acc: 0.7326\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.6123 - acc: 0.7326\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.6033 - acc: 0.7326\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5959 - acc: 0.7326\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.5901 - acc: 0.7326\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5857 - acc: 0.7326\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5818 - acc: 0.7326\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5783 - acc: 0.7326\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5754 - acc: 0.7326\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5727 - acc: 0.7326\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.5702 - acc: 0.7326\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.5681 - acc: 0.7326\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.5660 - acc: 0.7326\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5638 - acc: 0.7326\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.5621 - acc: 0.7326\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5602 - acc: 0.7326\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5584 - acc: 0.7333\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5565 - acc: 0.7333\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.5550 - acc: 0.7314\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.5532 - acc: 0.7326\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.5513 - acc: 0.7333\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5490 - acc: 0.7326\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.5470 - acc: 0.7339\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5451 - acc: 0.7365\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5428 - acc: 0.7365\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5412 - acc: 0.7384\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.5393 - acc: 0.7384\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5376 - acc: 0.7397\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5358 - acc: 0.7410\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5342 - acc: 0.7436\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5325 - acc: 0.7429\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.5310 - acc: 0.7423\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5296 - acc: 0.7429\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5283 - acc: 0.7449\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5267 - acc: 0.7442\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.5253 - acc: 0.7449\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5239 - acc: 0.7481\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.5225 - acc: 0.7461\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5212 - acc: 0.7487\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.5199 - acc: 0.7455\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5187 - acc: 0.7487\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5175 - acc: 0.7487\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.5163 - acc: 0.7494\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.5151 - acc: 0.7481\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.5137 - acc: 0.7468\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5127 - acc: 0.7468\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.5111 - acc: 0.7494\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.5098 - acc: 0.7500\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.5087 - acc: 0.7481\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.5075 - acc: 0.7532\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.5064 - acc: 0.7526\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.5052 - acc: 0.7539\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.5040 - acc: 0.7545\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.5027 - acc: 0.7539\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5017 - acc: 0.7558\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.5006 - acc: 0.7545\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4989 - acc: 0.7571\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4976 - acc: 0.7603\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4963 - acc: 0.7571\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4951 - acc: 0.7571\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4942 - acc: 0.7571\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4930 - acc: 0.7584\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4916 - acc: 0.7590\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.4905 - acc: 0.7584\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4895 - acc: 0.7551\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4883 - acc: 0.7584\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.4875 - acc: 0.7571\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4867 - acc: 0.7584\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4857 - acc: 0.7571\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.4845 - acc: 0.7629\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4840 - acc: 0.7654\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4830 - acc: 0.7706\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.4823 - acc: 0.7661\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4816 - acc: 0.7654\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 60us/step - loss: 0.4807 - acc: 0.7674\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4801 - acc: 0.7674\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4791 - acc: 0.7667\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4786 - acc: 0.7686\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4781 - acc: 0.7693\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4774 - acc: 0.7667\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4770 - acc: 0.7706\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4757 - acc: 0.7706\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4749 - acc: 0.7731\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4746 - acc: 0.7738\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4738 - acc: 0.7744\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4733 - acc: 0.7751\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4727 - acc: 0.7763\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4722 - acc: 0.7738\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4719 - acc: 0.7731\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4711 - acc: 0.7770\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4712 - acc: 0.7770\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4702 - acc: 0.7783\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4698 - acc: 0.7751\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4692 - acc: 0.7789\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4685 - acc: 0.7770\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4689 - acc: 0.7789\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4680 - acc: 0.7796\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4670 - acc: 0.7789\n",
      "\n",
      "Accuracy Score: 80.77%\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 313us/step - loss: 0.6193 - acc: 0.7275\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.5483 - acc: 0.7442\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.5387 - acc: 0.7449\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.5066 - acc: 0.7449\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.4851 - acc: 0.7629\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4850 - acc: 0.7635\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4851 - acc: 0.7731\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4813 - acc: 0.7674\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4788 - acc: 0.7680\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4834 - acc: 0.7693\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4708 - acc: 0.7712\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4604 - acc: 0.7763\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4676 - acc: 0.7757\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.5191 - acc: 0.7301\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.5013 - acc: 0.7404\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4864 - acc: 0.7513\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4851 - acc: 0.7532\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.4805 - acc: 0.7680\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4762 - acc: 0.7577\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4679 - acc: 0.7770\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4739 - acc: 0.7783\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4676 - acc: 0.7667\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4674 - acc: 0.7674\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4736 - acc: 0.7770\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4684 - acc: 0.7860\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4532 - acc: 0.7898\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4747 - acc: 0.7725\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.5005 - acc: 0.7571\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4553 - acc: 0.7808\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4496 - acc: 0.7757\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4546 - acc: 0.7879\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4434 - acc: 0.7988\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4404 - acc: 0.7969\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.4446 - acc: 0.7937\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4446 - acc: 0.7937\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4339 - acc: 0.8001\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4374 - acc: 0.8001\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4544 - acc: 0.7982\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4402 - acc: 0.8001\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4368 - acc: 0.7969\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4457 - acc: 0.8021\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4712 - acc: 0.7667\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4545 - acc: 0.7821\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4431 - acc: 0.7931\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.4421 - acc: 0.7982\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4491 - acc: 0.7937\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 53us/step - loss: 0.4412 - acc: 0.7918\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.4318 - acc: 0.8040\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.4308 - acc: 0.8053\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4353 - acc: 0.8072\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4465 - acc: 0.7886\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.4813 - acc: 0.7808\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.4674 - acc: 0.7789\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.4589 - acc: 0.7873\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.4514 - acc: 0.7982\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4467 - acc: 0.7937\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4549 - acc: 0.7821\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4625 - acc: 0.7860\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4276 - acc: 0.7950\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4306 - acc: 0.8104\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4325 - acc: 0.7905\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4253 - acc: 0.8201\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4155 - acc: 0.8207\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4245 - acc: 0.8066\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4500 - acc: 0.7892\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4288 - acc: 0.8008\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4271 - acc: 0.7988\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4643 - acc: 0.7776\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4236 - acc: 0.8008\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4573 - acc: 0.7950\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4441 - acc: 0.7988\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4300 - acc: 0.8085\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4244 - acc: 0.8143\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4285 - acc: 0.8111\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.4235 - acc: 0.8201\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4127 - acc: 0.8265\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4197 - acc: 0.8091\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4240 - acc: 0.8014\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4353 - acc: 0.8123\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4196 - acc: 0.8233\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4158 - acc: 0.8143\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4236 - acc: 0.8181\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4239 - acc: 0.8162\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4365 - acc: 0.8136\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4381 - acc: 0.8040\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4339 - acc: 0.7963\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4486 - acc: 0.7995\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4406 - acc: 0.8072\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4277 - acc: 0.8033\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4220 - acc: 0.8123\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.6961 - acc: 0.7596\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4470 - acc: 0.7937\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 61us/step - loss: 0.4283 - acc: 0.8085\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.4402 - acc: 0.7937\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4236 - acc: 0.8104\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4208 - acc: 0.8194\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4281 - acc: 0.8188\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.4238 - acc: 0.8162\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4367 - acc: 0.7988\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4161 - acc: 0.8117\n",
      "\n",
      "Accuracy Score: 59.49%\n"
     ]
    }
   ],
   "source": [
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    model.compile(optimizer = my_optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred = (Y_pred > 0.5)\n",
    "    acs = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.900000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 427us/step - loss: 0.4650 - acc: 0.7918\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4372 - acc: 0.8021\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4201 - acc: 0.8117\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4232 - acc: 0.8156\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4200 - acc: 0.8053\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4128 - acc: 0.8098\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.4011 - acc: 0.8181\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4231 - acc: 0.8168\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4085 - acc: 0.8207\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4634 - acc: 0.8046\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4365 - acc: 0.8033\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.4256 - acc: 0.8130\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4137 - acc: 0.8143\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4223 - acc: 0.8136\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4012 - acc: 0.8271\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4345 - acc: 0.7982\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4274 - acc: 0.8046\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.4219 - acc: 0.8091\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4228 - acc: 0.8123\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4205 - acc: 0.8066\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4195 - acc: 0.8111\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4246 - acc: 0.8078\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4140 - acc: 0.8201\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4214 - acc: 0.8104\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4184 - acc: 0.8123\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4247 - acc: 0.8072\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4554 - acc: 0.7789\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4138 - acc: 0.8168\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4208 - acc: 0.8136\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4060 - acc: 0.8226\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4140 - acc: 0.8188\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4412 - acc: 0.7898\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3997 - acc: 0.8149\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4067 - acc: 0.8226\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4077 - acc: 0.8149\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4031 - acc: 0.8168\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.4011 - acc: 0.8233\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.4080 - acc: 0.8201\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4034 - acc: 0.8085\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4049 - acc: 0.8194\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.3924 - acc: 0.8329\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4038 - acc: 0.8143\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3921 - acc: 0.8329\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3902 - acc: 0.8290\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3851 - acc: 0.8284\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3909 - acc: 0.8226\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.4508 - acc: 0.7866\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4505 - acc: 0.8040\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4176 - acc: 0.8194\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4149 - acc: 0.8104\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.4043 - acc: 0.8213\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3992 - acc: 0.8246\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4060 - acc: 0.8181\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.4244 - acc: 0.8149\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.4108 - acc: 0.8246\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4188 - acc: 0.8168\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4204 - acc: 0.8149\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.4018 - acc: 0.8175\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.4147 - acc: 0.8201\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4011 - acc: 0.8246\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3971 - acc: 0.8290\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4001 - acc: 0.8220\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.4003 - acc: 0.8252\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3939 - acc: 0.8258\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3986 - acc: 0.8181\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.4115 - acc: 0.8168\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3975 - acc: 0.8201\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3990 - acc: 0.8239\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.3960 - acc: 0.8284\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3960 - acc: 0.8297\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4191 - acc: 0.8168\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4009 - acc: 0.8252\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3953 - acc: 0.8175\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4187 - acc: 0.8207\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3958 - acc: 0.8258\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3970 - acc: 0.8220\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3937 - acc: 0.8258\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3956 - acc: 0.8175\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3797 - acc: 0.8252\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.4006 - acc: 0.8233\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3924 - acc: 0.8323\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3939 - acc: 0.8278\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3864 - acc: 0.8316\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3950 - acc: 0.8316: 0s - loss: 0.3964 - acc: 0.833\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.4105 - acc: 0.8046\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3971 - acc: 0.8194\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.4054 - acc: 0.8136\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3987 - acc: 0.8149\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3969 - acc: 0.8239\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3860 - acc: 0.8310\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3810 - acc: 0.8310\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.4029 - acc: 0.8162\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3889 - acc: 0.8271\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3970 - acc: 0.8226\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3875 - acc: 0.8258\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.4120 - acc: 0.8220\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3982 - acc: 0.8265\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.3842 - acc: 0.8239\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3827 - acc: 0.8303\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3848 - acc: 0.8278\n",
      "\n",
      "Accuracy Score: 80.51%\n",
      "==============================================================\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.020000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 716us/step - loss: 0.3879 - acc: 0.8239\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3800 - acc: 0.8278\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3756 - acc: 0.8297\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3722 - acc: 0.8297\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3698 - acc: 0.8310\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3684 - acc: 0.8329\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3673 - acc: 0.8316\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 59us/step - loss: 0.3665 - acc: 0.8329\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3658 - acc: 0.8335\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.3650 - acc: 0.8335\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3642 - acc: 0.8361\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3636 - acc: 0.8361\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3630 - acc: 0.8380\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3623 - acc: 0.8374\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3618 - acc: 0.8374\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3613 - acc: 0.8368\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3609 - acc: 0.8380\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3603 - acc: 0.8380\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3599 - acc: 0.8380\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3595 - acc: 0.8387\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3590 - acc: 0.8406\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3586 - acc: 0.8406\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3581 - acc: 0.8400\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3578 - acc: 0.8406\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3577 - acc: 0.8425\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - ETA: 0s - loss: 0.2619 - acc: 0.860 - 0s 32us/step - loss: 0.3571 - acc: 0.8425\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3566 - acc: 0.8425\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3561 - acc: 0.8419\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.3558 - acc: 0.8419\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3553 - acc: 0.8438\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3549 - acc: 0.8438\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3546 - acc: 0.8438\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3543 - acc: 0.8432\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3542 - acc: 0.8445\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3537 - acc: 0.8432\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3534 - acc: 0.8445\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3529 - acc: 0.8458\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3527 - acc: 0.8451\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3524 - acc: 0.8445\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3521 - acc: 0.8464\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3519 - acc: 0.8445\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 56us/step - loss: 0.3517 - acc: 0.8445\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3515 - acc: 0.8451\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3512 - acc: 0.8458\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3509 - acc: 0.8458\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3506 - acc: 0.8458\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3504 - acc: 0.8451\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3506 - acc: 0.8445\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3500 - acc: 0.8458\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3502 - acc: 0.8464\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3495 - acc: 0.8470\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3492 - acc: 0.8464\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3490 - acc: 0.8458\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3487 - acc: 0.8470\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3486 - acc: 0.8470\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3484 - acc: 0.8470\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3484 - acc: 0.8458\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3479 - acc: 0.8464\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3477 - acc: 0.8470\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3474 - acc: 0.8477\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3473 - acc: 0.8470\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.3471 - acc: 0.8470\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.3471 - acc: 0.8464\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 56us/step - loss: 0.3467 - acc: 0.8470\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3465 - acc: 0.8477\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3468 - acc: 0.8464\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3462 - acc: 0.8477\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3459 - acc: 0.8477\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3457 - acc: 0.8458\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3454 - acc: 0.8483\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3452 - acc: 0.8477\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3451 - acc: 0.8470\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3450 - acc: 0.8477\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3448 - acc: 0.8470\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 63us/step - loss: 0.3446 - acc: 0.8470\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 61us/step - loss: 0.3444 - acc: 0.8477\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3443 - acc: 0.8477\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.3441 - acc: 0.8477\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3439 - acc: 0.8477\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3439 - acc: 0.8464\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 59us/step - loss: 0.3437 - acc: 0.8490\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3435 - acc: 0.8483\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.3433 - acc: 0.8490\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3434 - acc: 0.8477\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3433 - acc: 0.8470\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3429 - acc: 0.8490\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3428 - acc: 0.8470\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3430 - acc: 0.8483\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3425 - acc: 0.8477\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3423 - acc: 0.8477\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 57us/step - loss: 0.3421 - acc: 0.8477\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3420 - acc: 0.8496\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.3417 - acc: 0.8496\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3415 - acc: 0.8496\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 60us/step - loss: 0.3414 - acc: 0.8490\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.3414 - acc: 0.8503\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3412 - acc: 0.8496\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3410 - acc: 0.8503\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3409 - acc: 0.8496\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3408 - acc: 0.8509\n",
      "\n",
      "Accuracy Score: 81.79%\n",
      "==============================================================\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.050000\n",
      "\n",
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 1s 553us/step - loss: 0.3418 - acc: 0.8483\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3415 - acc: 0.8496\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3425 - acc: 0.8490\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3409 - acc: 0.8477\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3405 - acc: 0.8496\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3396 - acc: 0.8503\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3390 - acc: 0.8496\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3384 - acc: 0.8470\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3384 - acc: 0.8515\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.3382 - acc: 0.8503\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3372 - acc: 0.8509\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3383 - acc: 0.8522\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3368 - acc: 0.8509\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3360 - acc: 0.8515\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.3359 - acc: 0.8503\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3352 - acc: 0.8503\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3349 - acc: 0.8522\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3343 - acc: 0.8509\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3350 - acc: 0.8528\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 35us/step - loss: 0.3353 - acc: 0.8496\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3338 - acc: 0.8528\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3332 - acc: 0.8503\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.3329 - acc: 0.8548\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3325 - acc: 0.8554\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3321 - acc: 0.8535\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3316 - acc: 0.8522\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3314 - acc: 0.8515\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.3312 - acc: 0.8528\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3313 - acc: 0.8522\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3311 - acc: 0.8535\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3320 - acc: 0.8503\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3306 - acc: 0.8567\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3302 - acc: 0.8560\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3296 - acc: 0.8586\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3298 - acc: 0.8548\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.3283 - acc: 0.8567\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3274 - acc: 0.8567\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3275 - acc: 0.8580\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3268 - acc: 0.8580\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3265 - acc: 0.8580\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3261 - acc: 0.8567\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3268 - acc: 0.8548\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3260 - acc: 0.8554\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3258 - acc: 0.8599\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3253 - acc: 0.8593\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.3249 - acc: 0.8580\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3252 - acc: 0.8586\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.3247 - acc: 0.8586\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3238 - acc: 0.8618\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 60us/step - loss: 0.3239 - acc: 0.8599\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 58us/step - loss: 0.3237 - acc: 0.8599\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3236 - acc: 0.8593\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 56us/step - loss: 0.3232 - acc: 0.8605\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3231 - acc: 0.8618\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.3229 - acc: 0.8605\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 68us/step - loss: 0.3220 - acc: 0.8586\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3228 - acc: 0.8593\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3221 - acc: 0.8618\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3215 - acc: 0.8586\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3210 - acc: 0.8599\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3233 - acc: 0.8541\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.3214 - acc: 0.8560\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 53us/step - loss: 0.3213 - acc: 0.8580\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 68us/step - loss: 0.3206 - acc: 0.8593\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 56us/step - loss: 0.3205 - acc: 0.8599\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 54us/step - loss: 0.3200 - acc: 0.8554\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 53us/step - loss: 0.3216 - acc: 0.8605\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.3208 - acc: 0.8605\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 51us/step - loss: 0.3193 - acc: 0.8599\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 53us/step - loss: 0.3189 - acc: 0.8605\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 55us/step - loss: 0.3190 - acc: 0.8605\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3196 - acc: 0.8593\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3197 - acc: 0.8593\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3189 - acc: 0.8580\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.3180 - acc: 0.8599\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.3186 - acc: 0.8593\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3181 - acc: 0.8612\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.3171 - acc: 0.8618\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3193 - acc: 0.8593\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 56us/step - loss: 0.3182 - acc: 0.8580\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 52us/step - loss: 0.3185 - acc: 0.8580\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3176 - acc: 0.8593\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3177 - acc: 0.8605\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3172 - acc: 0.8567\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3183 - acc: 0.8599\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3175 - acc: 0.8605\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3197 - acc: 0.8554\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3185 - acc: 0.8618\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 50us/step - loss: 0.3177 - acc: 0.8605\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3161 - acc: 0.8612\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 33us/step - loss: 0.3169 - acc: 0.8612\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3150 - acc: 0.8612\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3168 - acc: 0.8599\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 48us/step - loss: 0.3166 - acc: 0.8593\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.3163 - acc: 0.8580\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3144 - acc: 0.8605\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.3145 - acc: 0.8612\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.3132 - acc: 0.8638\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.3144 - acc: 0.8605\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.3148 - acc: 0.8599\n",
      "\n",
      "Accuracy Score: 82.31%\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "lr_to_test = [0.9,.02,0.05]\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    model.compile(optimizer = my_optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred = (Y_pred > 0.5)\n",
    "    acs = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))\n",
    "    print('==============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(names):\n",
    "    df = pd.read_csv('character-predictions.csv', usecols= [5,7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "    sur=[]\n",
    "    dead=[]\n",
    "    for name in names:\n",
    "        parameters = df.loc[df['name'] == name]\n",
    "        parameters.drop(parameters.columns[0], axis=1, inplace=True)\n",
    "        inputFeature = np.asarray(parameters).reshape(1, 12)\n",
    "        raw_prediction = model.predict(inputFeature)[0][0]\n",
    "        if raw_prediction > 0.5:\n",
    "            sur.append(name)\n",
    "        else:\n",
    "            dead.append(name)\n",
    "            \n",
    "    print('Survivors :')\n",
    "    print(sur)\n",
    "    print('')\n",
    "    print('Dead :')\n",
    "    print(dead)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tSurviving Lannisters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kash/.local/lib/python2.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survivors :\n",
      "[]\n",
      "\n",
      "Dead :\n",
      "['Tyrion Lannister', 'Jaime Lannister', 'Cersei Lannister']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tSurviving Starks\n",
      "Survivors :\n",
      "[]\n",
      "\n",
      "Dead :\n",
      "['Arya Stark', 'Sansa Stark', 'Brandon Stark']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tSurviving Targaryens\n",
      "Survivors :\n",
      "[]\n",
      "\n",
      "Dead :\n",
      "['Daenerys Targaryen', 'Jon Snow']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tOther Survivers\n",
      "Survivors :\n",
      "['Samwell Tarly', 'Daario Naharis', 'Missandei', 'Grey Worm', 'Gilly', 'Melisandre', 'Varys']\n",
      "\n",
      "Dead :\n",
      "['Jorah Mormont', 'Asha Greyjoy', 'Theon Greyjoy', 'Gendry', 'Sandor Clegane']\n",
      "\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('character-predictions.csv', usecols= [5,7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "\n",
    "Lannisters=['Tyrion Lannister','Jaime Lannister','Cersei Lannister']\n",
    "print('\\t\\t\\t\\tSurviving Lannisters')\n",
    "predictor(Lannisters)\n",
    "print('===========================================')\n",
    "Starks=['Arya Stark','Sansa Stark','Brandon Stark']\n",
    "print('\\t\\t\\t\\tSurviving Starks')\n",
    "predictor(Starks)\n",
    "print('===========================================')\n",
    "Targaryens=['Daenerys Targaryen','Jon Snow']\n",
    "print('\\t\\t\\t\\tSurviving Targaryens')\n",
    "predictor(Targaryens)\n",
    "print('===========================================')\n",
    "Misc=['Samwell Tarly','Daario Naharis','Jorah Mormont','Missandei','Grey Worm','Gilly','Melisandre',\\\n",
    "      'Asha Greyjoy','Theon Greyjoy','Gendry','Varys','Sandor Clegane']\n",
    "print('\\t\\t\\t\\tOther Survivers')\n",
    "predictor(Misc)\n",
    "print('===========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model, view=True, filename='network.gv', title='GoT CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
