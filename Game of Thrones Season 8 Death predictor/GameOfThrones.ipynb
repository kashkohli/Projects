{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeX = pd.read_csv('character-predictions.csv', usecols= [7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "dataframeY = pd.read_csv('character-predictions.csv', usecols=[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   male  book1  book2  book3  book4  book5  isMarried  isNoble  \\\n",
      "0     1      0      0      0      0      0          0        0   \n",
      "1     1      1      1      1      1      1          1        1   \n",
      "2     1      0      0      0      1      0          0        1   \n",
      "3     0      0      0      0      0      0          1        1   \n",
      "4     0      0      0      0      1      0          1        1   \n",
      "\n",
      "   numDeadRelations  boolDeadRelations  isPopular  popularity  \n",
      "0                11                  1          1    0.605351  \n",
      "1                 1                  1          1    0.896321  \n",
      "2                 0                  0          0    0.267559  \n",
      "3                 0                  0          0    0.183946  \n",
      "4                 0                  0          0    0.043478  \n",
      "   isAlive\n",
      "0        0\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n"
     ]
    }
   ],
   "source": [
    "print(dataframeX.head(5))\n",
    "print(dataframeY.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataframeX.values, dataframeY.values, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.05351171],\n",
      "       [1.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
      "        0.02675585],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01337793],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01337793],\n",
      "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
      "        0.16053512],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01003344]]), array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.01003344],\n",
      "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
      "        0.19063545],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.04013378],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.07692308],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.02675585]]))\n"
     ]
    }
   ],
   "source": [
    "print(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.78471906, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.2278903 ],\n",
      "       [ 0.78471906, -0.49678453,  1.2795656 , ..., -0.28907691,\n",
      "        -0.25499795, -0.39529137],\n",
      "       [ 0.78471906, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.47899191],\n",
      "       ...,\n",
      "       [-1.27434141, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.47899191],\n",
      "       [-1.27434141, -0.49678453,  1.2795656 , ..., -0.28907691,\n",
      "        -0.25499795,  0.44171397],\n",
      "       [-1.27434141, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.49991704]]), array([[-1.27434141, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.49991704],\n",
      "       [-1.27434141, -0.49678453,  1.2795656 , ..., -0.28907691,\n",
      "        -0.25499795,  0.63004017],\n",
      "       [ 0.78471906, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.56269244],\n",
      "       ...,\n",
      "       [ 0.78471906, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.31159084],\n",
      "       [ 0.78471906, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.08141437],\n",
      "       [-1.27434141, -0.49678453, -0.78151522, ..., -0.28907691,\n",
      "        -0.25499795, -0.39529137]]))\n"
     ]
    }
   ],
   "source": [
    "print(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(15, input_dim=12, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(50, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(9, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                195       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                800       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 459       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,585\n",
      "Trainable params: 1,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1 - Adam - Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 156us/step - loss: 0.2559 - acc: 0.4602\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.2421 - acc: 0.7513\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.2313 - acc: 0.7603\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.2121 - acc: 0.7539\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.1827 - acc: 0.7616\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1686 - acc: 0.7629\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1610 - acc: 0.7706\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.1572 - acc: 0.7686\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.1542 - acc: 0.7834\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1524 - acc: 0.7879\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1502 - acc: 0.7924\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1472 - acc: 0.7924\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1465 - acc: 0.7988\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.1447 - acc: 0.7976\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1431 - acc: 0.8008\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 49us/step - loss: 0.1421 - acc: 0.7982\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1431 - acc: 0.8053\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.1407 - acc: 0.8098: 0s - loss: 0.1405 - acc: 0.812\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1394 - acc: 0.8078\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 47us/step - loss: 0.1391 - acc: 0.8091\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1387 - acc: 0.8091\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.1380 - acc: 0.8175\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1368 - acc: 0.8130\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.1356 - acc: 0.8233\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.1372 - acc: 0.8162\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1346 - acc: 0.8168\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1335 - acc: 0.8213\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1330 - acc: 0.8239\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1342 - acc: 0.8188\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1317 - acc: 0.8290\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1337 - acc: 0.8284\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1306 - acc: 0.8355\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1292 - acc: 0.8348\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1303 - acc: 0.8316\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1289 - acc: 0.8368\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1276 - acc: 0.8303\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.1288 - acc: 0.8303\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1278 - acc: 0.8355\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1253 - acc: 0.8393\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1276 - acc: 0.8323\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1271 - acc: 0.8380\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1270 - acc: 0.8335\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1255 - acc: 0.8355\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1257 - acc: 0.8310\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1239 - acc: 0.8361\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1238 - acc: 0.8361\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.1227 - acc: 0.8361\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1245 - acc: 0.8380\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 44us/step - loss: 0.1229 - acc: 0.8329\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1242 - acc: 0.8284\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.1257 - acc: 0.8329\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1233 - acc: 0.8329\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1232 - acc: 0.8380\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.1208 - acc: 0.8419\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1211 - acc: 0.8400\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1215 - acc: 0.8380\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1200 - acc: 0.8419\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.1196 - acc: 0.8419\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1195 - acc: 0.8406\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1198 - acc: 0.8425\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1215 - acc: 0.8432\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1193 - acc: 0.8432\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1185 - acc: 0.8425\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1177 - acc: 0.8413\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1182 - acc: 0.8432\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1192 - acc: 0.8374\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1201 - acc: 0.8438\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 42us/step - loss: 0.1182 - acc: 0.8432\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1165 - acc: 0.8496\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1174 - acc: 0.8406\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1177 - acc: 0.8445\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1162 - acc: 0.8445\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1154 - acc: 0.8477\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1148 - acc: 0.8509\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1165 - acc: 0.8483\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 46us/step - loss: 0.1167 - acc: 0.8445\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1197 - acc: 0.8432\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1164 - acc: 0.8458\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1170 - acc: 0.8438\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1170 - acc: 0.8438\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 45us/step - loss: 0.1181 - acc: 0.8483\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1170 - acc: 0.8438\n",
      "Epoch 83/100\n",
      "1556/1556 [==============================] - 0s 43us/step - loss: 0.1156 - acc: 0.8477\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1160 - acc: 0.8387\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1145 - acc: 0.8483\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1130 - acc: 0.8445\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1141 - acc: 0.8477\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.1132 - acc: 0.8515\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1113 - acc: 0.8522\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 41us/step - loss: 0.1133 - acc: 0.8496\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.1126 - acc: 0.8483\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 37us/step - loss: 0.1129 - acc: 0.8490\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.1135 - acc: 0.8438\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 39us/step - loss: 0.1116 - acc: 0.8541\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.1127 - acc: 0.8451\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 40us/step - loss: 0.1133 - acc: 0.8509\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1121 - acc: 0.8458\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 36us/step - loss: 0.1126 - acc: 0.8470\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.1126 - acc: 0.8560\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.1123 - acc: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06f4bcf950>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=50,  verbose=1, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_meansqerror.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 30  60]\n",
      " [ 25 275]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 78.21%\n"
     ]
    }
   ],
   "source": [
    "acs = accuracy_score(Y_test, Y_pred)\n",
    "print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 - Adam - Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1556/1556 [==============================] - 0s 107us/step - loss: 0.6319 - acc: 0.7339\n",
      "Epoch 2/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.5669 - acc: 0.7339\n",
      "Epoch 3/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.5337 - acc: 0.7339\n",
      "Epoch 4/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5122 - acc: 0.7339\n",
      "Epoch 5/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.5028 - acc: 0.7339\n",
      "Epoch 6/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4960 - acc: 0.7339\n",
      "Epoch 7/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4928 - acc: 0.7339\n",
      "Epoch 8/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4874 - acc: 0.7339\n",
      "Epoch 9/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4842 - acc: 0.7506\n",
      "Epoch 10/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4824 - acc: 0.7706\n",
      "Epoch 11/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4809 - acc: 0.7828\n",
      "Epoch 12/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4745 - acc: 0.7853\n",
      "Epoch 13/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4734 - acc: 0.7866\n",
      "Epoch 14/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.4705 - acc: 0.7815\n",
      "Epoch 15/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4681 - acc: 0.7898\n",
      "Epoch 16/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.4642 - acc: 0.7937\n",
      "Epoch 17/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4604 - acc: 0.7956\n",
      "Epoch 18/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4631 - acc: 0.7931\n",
      "Epoch 19/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4561 - acc: 0.7956\n",
      "Epoch 20/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4552 - acc: 0.8014\n",
      "Epoch 21/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4504 - acc: 0.7943\n",
      "Epoch 22/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4472 - acc: 0.8033\n",
      "Epoch 23/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4461 - acc: 0.7995\n",
      "Epoch 24/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4432 - acc: 0.8059\n",
      "Epoch 25/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4396 - acc: 0.8040\n",
      "Epoch 26/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4380 - acc: 0.8085\n",
      "Epoch 27/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4348 - acc: 0.8072\n",
      "Epoch 28/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4353 - acc: 0.8040\n",
      "Epoch 29/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4324 - acc: 0.8104\n",
      "Epoch 30/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4294 - acc: 0.8091\n",
      "Epoch 31/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4274 - acc: 0.8136\n",
      "Epoch 32/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4314 - acc: 0.8162\n",
      "Epoch 33/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4240 - acc: 0.8078\n",
      "Epoch 34/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4249 - acc: 0.8201\n",
      "Epoch 35/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.4219 - acc: 0.8130\n",
      "Epoch 36/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4194 - acc: 0.8188\n",
      "Epoch 37/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4174 - acc: 0.8130\n",
      "Epoch 38/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4134 - acc: 0.8207\n",
      "Epoch 39/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4158 - acc: 0.8194\n",
      "Epoch 40/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4159 - acc: 0.8226\n",
      "Epoch 41/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4128 - acc: 0.8188\n",
      "Epoch 42/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4087 - acc: 0.8226\n",
      "Epoch 43/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4088 - acc: 0.8233\n",
      "Epoch 44/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4158 - acc: 0.8117\n",
      "Epoch 45/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4077 - acc: 0.8181\n",
      "Epoch 46/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4046 - acc: 0.8194\n",
      "Epoch 47/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4043 - acc: 0.8252\n",
      "Epoch 48/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.4021 - acc: 0.8201\n",
      "Epoch 49/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.4069 - acc: 0.8181\n",
      "Epoch 50/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.4004 - acc: 0.8246\n",
      "Epoch 51/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.4016 - acc: 0.8201\n",
      "Epoch 52/100\n",
      "1556/1556 [==============================] - 0s 30us/step - loss: 0.3978 - acc: 0.8258\n",
      "Epoch 53/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.3970 - acc: 0.8226\n",
      "Epoch 54/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3963 - acc: 0.8226\n",
      "Epoch 55/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3961 - acc: 0.8316\n",
      "Epoch 56/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3949 - acc: 0.8297\n",
      "Epoch 57/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3953 - acc: 0.8258\n",
      "Epoch 58/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3941 - acc: 0.8303\n",
      "Epoch 59/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3940 - acc: 0.8271\n",
      "Epoch 60/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3942 - acc: 0.8297\n",
      "Epoch 61/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3938 - acc: 0.8265\n",
      "Epoch 62/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3938 - acc: 0.8258\n",
      "Epoch 63/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3947 - acc: 0.8303\n",
      "Epoch 64/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3923 - acc: 0.8290\n",
      "Epoch 65/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3869 - acc: 0.8310\n",
      "Epoch 66/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3870 - acc: 0.8310\n",
      "Epoch 67/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3880 - acc: 0.8297\n",
      "Epoch 68/100\n",
      "1556/1556 [==============================] - 0s 23us/step - loss: 0.3875 - acc: 0.8329\n",
      "Epoch 69/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3880 - acc: 0.8297\n",
      "Epoch 70/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3840 - acc: 0.8368\n",
      "Epoch 71/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3872 - acc: 0.8335\n",
      "Epoch 72/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3830 - acc: 0.8348\n",
      "Epoch 73/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3813 - acc: 0.8329\n",
      "Epoch 74/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3881 - acc: 0.8329\n",
      "Epoch 75/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3817 - acc: 0.8361\n",
      "Epoch 76/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3819 - acc: 0.8393\n",
      "Epoch 77/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3795 - acc: 0.8342\n",
      "Epoch 78/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3893 - acc: 0.8335\n",
      "Epoch 79/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3786 - acc: 0.8406\n",
      "Epoch 80/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3757 - acc: 0.8406\n",
      "Epoch 81/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3813 - acc: 0.8323\n",
      "Epoch 82/100\n",
      "1556/1556 [==============================] - 0s 31us/step - loss: 0.3758 - acc: 0.8355\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3743 - acc: 0.8413\n",
      "Epoch 84/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3760 - acc: 0.8329\n",
      "Epoch 85/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3715 - acc: 0.8419\n",
      "Epoch 86/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3783 - acc: 0.8387\n",
      "Epoch 87/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3714 - acc: 0.8380\n",
      "Epoch 88/100\n",
      "1556/1556 [==============================] - 0s 38us/step - loss: 0.3778 - acc: 0.8323\n",
      "Epoch 89/100\n",
      "1556/1556 [==============================] - 0s 32us/step - loss: 0.3730 - acc: 0.8380\n",
      "Epoch 90/100\n",
      "1556/1556 [==============================] - 0s 34us/step - loss: 0.3705 - acc: 0.8400\n",
      "Epoch 91/100\n",
      "1556/1556 [==============================] - 0s 29us/step - loss: 0.3670 - acc: 0.8400\n",
      "Epoch 92/100\n",
      "1556/1556 [==============================] - 0s 27us/step - loss: 0.3672 - acc: 0.8419\n",
      "Epoch 93/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3733 - acc: 0.8406\n",
      "Epoch 94/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3708 - acc: 0.8400\n",
      "Epoch 95/100\n",
      "1556/1556 [==============================] - 0s 25us/step - loss: 0.3672 - acc: 0.8438\n",
      "Epoch 96/100\n",
      "1556/1556 [==============================] - 0s 26us/step - loss: 0.3697 - acc: 0.8413\n",
      "Epoch 97/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3689 - acc: 0.8451\n",
      "Epoch 98/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3668 - acc: 0.8413\n",
      "Epoch 99/100\n",
      "1556/1556 [==============================] - 0s 24us/step - loss: 0.3682 - acc: 0.8464\n",
      "Epoch 100/100\n",
      "1556/1556 [==============================] - 0s 28us/step - loss: 0.3694 - acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa48998bd10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=50, verbose=1, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_binarycrossentropy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 84.36%\n"
     ]
    }
   ],
   "source": [
    "acs = accuracy_score(Y_test, Y_pred)\n",
    "print(\"\\nAccuracy Score: %.2f%%\" % (acs * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(names):\n",
    "    df = pd.read_csv('character-predictions.csv', usecols= [5,7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "    sur=[]\n",
    "    dead=[]\n",
    "    for name in names:\n",
    "        parameters = df.loc[df['name'] == name]\n",
    "        parameters.drop(parameters.columns[0], axis=1, inplace=True)\n",
    "        inputFeature = np.asarray(parameters).reshape(1, 12)\n",
    "        raw_prediction = model.predict(inputFeature)[0][0]\n",
    "        if raw_prediction > 0.5:\n",
    "            sur.append(name)\n",
    "        else:\n",
    "            dead.append(name)\n",
    "            \n",
    "    print('Survivors :')\n",
    "    print(sur)\n",
    "    print('')\n",
    "    print('Dead :')\n",
    "    print(dead)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tSurviving Lannisters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kash/.local/lib/python2.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survivors :\n",
      "['Cersei Lannister']\n",
      "\n",
      "Dead :\n",
      "['Tyrion Lannister', 'Jaime Lannister']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tSurviving Starks\n",
      "Survivors :\n",
      "['Arya Stark', 'Sansa Stark']\n",
      "\n",
      "Dead :\n",
      "['Brandon Stark']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tSurviving Targaryens\n",
      "Survivors :\n",
      "['Daenerys Targaryen']\n",
      "\n",
      "Dead :\n",
      "['Jon Snow']\n",
      "\n",
      "===========================================\n",
      "\t\t\t\tOther Survivers\n",
      "Survivors :\n",
      "['Samwell Tarly', 'Daario Naharis', 'Jorah Mormont', 'Missandei', 'Grey Worm', 'Melisandre', 'Asha Greyjoy', 'Varys']\n",
      "\n",
      "Dead :\n",
      "['Gilly', 'Theon Greyjoy', 'Gendry', 'Sandor Clegane']\n",
      "\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('character-predictions.csv', usecols= [5,7, 16, 17, 18, 19, 20, 25, 26, 28, 29, 30, 31])\n",
    "\n",
    "Lannisters=['Tyrion Lannister','Jaime Lannister','Cersei Lannister']\n",
    "print('\\t\\t\\t\\tSurviving Lannisters')\n",
    "predictor(Lannisters)\n",
    "print('===========================================')\n",
    "Starks=['Arya Stark','Sansa Stark','Brandon Stark']\n",
    "print('\\t\\t\\t\\tSurviving Starks')\n",
    "predictor(Starks)\n",
    "print('===========================================')\n",
    "Targaryens=['Daenerys Targaryen','Jon Snow']\n",
    "print('\\t\\t\\t\\tSurviving Targaryens')\n",
    "predictor(Targaryens)\n",
    "print('===========================================')\n",
    "Misc=['Samwell Tarly','Daario Naharis','Jorah Mormont','Missandei','Grey Worm','Gilly','Melisandre',\\\n",
    "      'Asha Greyjoy','Theon Greyjoy','Gendry','Varys','Sandor Clegane']\n",
    "print('\\t\\t\\t\\tOther Survivers')\n",
    "predictor(Misc)\n",
    "print('===========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model, view=True, filename='network.gv', title='GoT CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
